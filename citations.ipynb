{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "801eb312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1a35c6cd110ec86b8d550c96ce7d7be1973db0be\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import os \n",
    "import re\n",
    "from pprint import pprint\n",
    "from dotenv import load_dotenv, dotenv_values\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80957859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eyecite import get_citations, clean_text, resolve_citations, annotate_citations\n",
    "from eyecite.models import FullCaseCitation, Resource\n",
    "from eyecite.resolve import resolve_full_citation\n",
    "from eyecite.tokenizers import HyperscanTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a141ca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eyecite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff9cc450",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/curtiswadsworth/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/curtiswadsworth/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb205f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def citation_parser(citation):\n",
    "\n",
    "    pattern = re.compile(r\"(?P<VOLUME>\\d+)\\s+(?P<REPORTER>[A-Za-z.\\s]+)\\s+(?P<PAGE>\\d+)\")\n",
    "    match = pattern.match(citation)\n",
    "\n",
    "    if match:\n",
    "        volume = match.group(\"VOLUME\")\n",
    "        reporter = match.group(\"REPORTER\")\n",
    "        page = match.group(\"PAGE\")\n",
    "        \n",
    "        #print(f\"Volume: {volume}\")\n",
    "        #print(f\"Reporter: {reporter}\")\n",
    "        #print(f\"Page: {page}\")\n",
    "        return volume, reporter, page\n",
    "    \n",
    "    else:\n",
    "        print(\"Invalid citation format\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a58783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_by_citation(volume, reporter, page, token='your_api_token'):\n",
    "    base_url = \"https://www.courtlistener.com/api/rest/v3/clusters/\"\n",
    "    \n",
    "    headers = {\n",
    "        'Authorization': f'Token {token}',\n",
    "        'Accept': 'application/json',\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        'citations__volume': volume,\n",
    "        'citations__reporter': reporter,\n",
    "        'citations__page': page,\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url, params=params, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        api_data = response.json()\n",
    "        results = api_data.get('results', [])\n",
    "        print(f\"Cluster results: {results}\")\n",
    "\n",
    "        if results:\n",
    "            # Return the first cluster found\n",
    "            opinion_id = results[0]['id']\n",
    "            print(f\"Opinion Id: {opinion_id}\")\n",
    "            return opinion_id\n",
    "    \n",
    "    print(f\"No cluster found for the specified citation.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0aa646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opinion_text(cite, search_by='id', token='your_api_token'):\n",
    "    base_url = \"https://www.courtlistener.com\"\n",
    "\n",
    "    headers = {\n",
    "        'Authorization': f'Token {token}',\n",
    "        'Accept': 'application/json',\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        search_by: cite\n",
    "    }\n",
    "\n",
    "    #search_url = \"/api/rest/v3/opinions/\"\n",
    "    search_url = \"/api/rest/v3/clusters/\"\n",
    "    response = requests.get(base_url + search_url, params=params, headers=headers)\n",
    "    \n",
    "    print(f\"API URL: {response.url}\")  # Print the API URL for debugging\n",
    "    print(f\"Request Headers: {response.request.headers}\")  # Print the headers being sent\n",
    "    print(f\"API Status Code: {response.status_code}\")  # Print the API status code\n",
    "    #print(f\"API Response Content: {response.text}\")\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        api_data = response.json()\n",
    "        print(f\"Parsed API Data: {api_data}\")\n",
    "        results = api_data.get('results', [])\n",
    "\n",
    "        if results:\n",
    "            first_result = results[0]\n",
    "            plain_text = first_result.get('plain_text', '')\n",
    "            html_content = first_result.get('html', '')\n",
    "            if not html_content:  # If 'html' is empty, try 'html_lawbox'\n",
    "                html_content = first_result.get('html_lawbox', '')\n",
    "\n",
    "            return plain_text, html_content\n",
    "\n",
    "        else: \n",
    "            print(f\"No results text\")\n",
    "            return None\n",
    "\n",
    "    print(f\"No results found for {search_by}: {citation}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4e0268",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEST\n",
    "\n",
    "def get_opinion_text(cite, search_by='docket_id', token='your_api_token'):\n",
    "    base_url = \"https://www.courtlistener.com\"\n",
    "\n",
    "    headers = {\n",
    "        'Authorization': f'Token {token}',\n",
    "        'Accept': 'application/json',\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        search_by: cite\n",
    "    }\n",
    "    \n",
    "    search_url = \"/api/rest/v3/dockets/\"\n",
    "    #search_url = \"/api/rest/v3/opinions/\" #retrieves opinion for 641 F. Supp. 828 (Poloroid)\n",
    "    #search_url = \"/api/rest/v3/clusters/\"\n",
    "    response = requests.get(base_url + search_url, params=params, headers=headers)\n",
    "    \n",
    "    print(f\"API URL: {response.url}\")  # Print the API URL for debugging\n",
    "    print(f\"Request Headers: {response.request.headers}\")  # Print the headers being sent\n",
    "    print(f\"API Status Code: {response.status_code}\")  # Print the API status code\n",
    "    print(f\"API Response Content: {response.text}\")\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        api_data = response.json()\n",
    "        print(f\"Parsed API Data: {api_data}\")\n",
    "        results = api_data.get('results', [])\n",
    "\n",
    "        if results:\n",
    "            first_result = results[0]\n",
    "            plain_text = first_result.get('plain_text', '')\n",
    "            html_content = first_result.get('html', '')\n",
    "\n",
    "            if not html_content:\n",
    "                html_content = first_result.get('html_lawbox', '')\n",
    "\n",
    "            if not html_content:\n",
    "                html_content = first_result.get('html_columbia', '')\n",
    "\n",
    "            if not html_content:\n",
    "                html_content = first_result.get('html_anon_2020', '')\n",
    "\n",
    "            if not html_content:\n",
    "                html_content = first_result.get('xml_harvard', '')\n",
    "\n",
    "            if not html_content:\n",
    "                html_content = first_result.get('html_with_citations', '')\n",
    "\n",
    "            return plain_text, html_content\n",
    "\n",
    "        else:\n",
    "            print(f\"No results text\")\n",
    "            return None\n",
    "    \n",
    "    print(f\"No results found for {search_by}: {citation}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62676710",
   "metadata": {},
   "outputs": [],
   "source": [
    "docket_id = '63778697'\n",
    "search_field = 'id'\n",
    "api_token = os.getenv(\"COURTLISTENER_API_KEY\")\n",
    "\n",
    "result = get_opinion_text(cite, search_by=search_field, token=api_token)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502d8a23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "citation = \"641 F. Supp. 828\"\n",
    "api_token = os.getenv(\"COURTLISTENER_API_KEY\")\n",
    "\n",
    "opinion_text = get_opinion_text_from_citation(citation, api_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6839ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(opinion_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aea7839",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "citation = \"561 U.S. 593\"\n",
    "api_token = os.getenv(\"COURTLISTENER_API_KEY\")\n",
    "\n",
    "opinion_text = get_opinion_text_from_citation(citation, api_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f41f060",
   "metadata": {},
   "outputs": [],
   "source": [
    "cite = \"641 F. Supp. 828\"\n",
    "your_api_token = os.getenv(\"COURTLISTENER_API_KEY\")  # Replace with your CourtListener API token\n",
    "\n",
    "parsed_citations = citation_parser(cite)\n",
    "\n",
    "volume = parsed_citations[0]\n",
    "reporter = parsed_citations[1]\n",
    "page = parsed_citations[2]\n",
    "\n",
    "citation_id = get_cluster_by_citation(volume, reporter, page, token=your_api_token)\n",
    "\n",
    "opinion_text = get_opinion_text(citation_id, search_by='id', token=your_api_token)\n",
    "\n",
    "print(f\"Opinion HTML: {opinion_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29346521",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.courtlistener.com/api/rest/v3/opinions/\"\n",
    "response = requests.options(url)\n",
    "\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(\"Headers:\")\n",
    "pprint(dict(response.headers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73174d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cite = \"6797301\"\n",
    "search_type = 'id' \n",
    "#cite = \"641 F. Supp. 828\"\n",
    "#search_type = 'citation'\n",
    "#search_type = 'citations' \n",
    "\n",
    "your_api_token = os.getenv('COURTLISTENER_API_KEY')  # Replace with your CourtListener API token\n",
    "\n",
    "opinion_text_by_name = get_opinion_text(cite, search_by=search_type, token=your_api_token)\n",
    "\n",
    "pprint(opinion_text_by_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e36ed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import quote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fa6a01",
   "metadata": {},
   "source": [
    "## Opinions By docket_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb71306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def citation_parser(citation):\n",
    "\n",
    "    pattern = re.compile(r\"(?P<VOLUME>\\d+)\\s+(?P<REPORTER>[A-Za-z.\\s]+)\\s+(?P<PAGE>\\d+)\")\n",
    "    match = pattern.match(citation)\n",
    "\n",
    "    if match:\n",
    "        volume = match.group(\"VOLUME\")\n",
    "        reporter = match.group(\"REPORTER\")\n",
    "        page = match.group(\"PAGE\")\n",
    "        \n",
    "        #print(f\"Volume: {volume}\")\n",
    "        #print(f\"Reporter: {reporter}\")\n",
    "        #print(f\"Page: {page}\")\n",
    "        return volume, reporter, page\n",
    "    \n",
    "    else:\n",
    "        print(\"Invalid citation format\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342359b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_by_citation(volume, reporter, page, token='API_token'):\n",
    "    base_url = \"https://www.courtlistener.com/api/rest/v3/clusters/\"\n",
    "    \n",
    "    headers = {\n",
    "        'Authorization': f'Token {token}',\n",
    "        'Accept': 'application/json',\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        'citations__volume': volume,\n",
    "        'citations__reporter': reporter,\n",
    "        'citations__page': page,\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url, params=params, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        api_data = response.json()\n",
    "        results = api_data.get('results', [])\n",
    "        #print(f\"Cluster results: {results}\")\n",
    "\n",
    "        if results:\n",
    "            # Return the first cluster found\n",
    "            docket_id = results[0]['docket_id']\n",
    "            print(f\"Docket Id: {docket_id}\")\n",
    "            return docket_id\n",
    "    \n",
    "    print(f\"No cluster found for the specified citation.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d36d344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opinion_text(docket_id, token='API_token'):\n",
    "    \n",
    "    base_url = \"https://www.courtlistener.com\"\n",
    "\n",
    "    headers = {\n",
    "        'Authorization': f'Token {API_token}',\n",
    "        'Accept': 'application/json',\n",
    "    }\n",
    "\n",
    "    search_url = f\"/api/rest/v3/opinions/?cluster__docket={docket_id}\"\n",
    "\n",
    "    response = requests.get(base_url + search_url, headers=headers)\n",
    "\n",
    "    print(f\"API URL: {response.url}\")  # Print the API URL for debugging\n",
    "    print(f\"Request Headers: {response.request.headers}\")  # Print the headers being sent\n",
    "    print(f\"API Status Code: {response.status_code}\")  # Print the API status code\n",
    "    #print(f\"API Response Content: {response.text}\")\n",
    "\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        api_data = response.json()\n",
    "        results = api_data.get('results', [])\n",
    "\n",
    "        print(f\"Number of Results: {api_data['count']}\")\n",
    "\n",
    "        result_texts = []\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            api_data = response.json()\n",
    "            results = api_data.get('results', [])\n",
    "\n",
    "            for i, result in enumerate(results, 1):\n",
    "                print(f\"Result {i} - Absolute URL: {result['absolute_url']}\")\n",
    "\n",
    "                plain_text = result.get('plain_text', '')\n",
    "                html_content = result.get('html', '')\n",
    "\n",
    "                if not html_content:\n",
    "                    html_content = result.get('html_lawbox', '')\n",
    "\n",
    "                if not html_content:\n",
    "                    html_content = result.get('html_columbia', '')\n",
    "\n",
    "                if not html_content:\n",
    "                    html_content = result.get('html_anon_2020', '')\n",
    "\n",
    "                if not html_content:\n",
    "                    html_content = result.get('xml_harvard', '')\n",
    "\n",
    "                if not html_content:\n",
    "                    html_content = result.get('html_with_citations', '')\n",
    "                \n",
    "                result_texts.append({'plain_text': plain_text, 'html_content': html_content})\n",
    "\n",
    "            return result_texts\n",
    "\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4778e907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opinion_text_from_citation(citation, token='API_token'):\n",
    "    \n",
    "    parsed_citations = citation_parser(citation)\n",
    "\n",
    "    volume = parsed_citations[0]\n",
    "    reporter = parsed_citations[1]\n",
    "    page = parsed_citations[2]\n",
    "\n",
    "    docket_id = get_cluster_by_citation(volume, reporter, page, token=token)\n",
    "\n",
    "    opinion_text = get_opinion_text(docket_id, token=token)\n",
    "\n",
    "    #print(f\"Opinion HTML: {opinion_text}\")\n",
    "    return opinion_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4637b306",
   "metadata": {},
   "outputs": [],
   "source": [
    "citation = '641 F. Supp. 828'\n",
    "API_token = os.getenv(\"COURTLISTENER_API_KEY\")\n",
    "\n",
    "result = get_opinion_text_from_citation(citation, token=API_token)\n",
    "\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d3f784",
   "metadata": {},
   "outputs": [],
   "source": [
    "citation = '561 U.S. 593'\n",
    "API_token = os.getenv(\"COURTLISTENER_API_KEY\")\n",
    "\n",
    "result = get_opinion_text_from_citation(citation, token=API_token)\n",
    "\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0899c072",
   "metadata": {},
   "outputs": [],
   "source": [
    "docket_id = '967127'\n",
    "API_token = os.getenv(\"COURTLISTENER_API_KEY\")\n",
    "\n",
    "result = get_opinion_text(docket_id, token=API_token)\n",
    "\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31228680",
   "metadata": {},
   "source": [
    "## Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105bea3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_references(html_text):\n",
    "    \n",
    "    statutes = re.findall(r'\\b\\d+\\sU\\.S\\.C\\.\\s§\\s\\d+\\b', html_text, re.IGNORECASE)\n",
    "    \n",
    "    citations = re.findall(r'\\b(\\d+\\s[A-Za-z\\s\\.\\d+]+(?:\\d+)?(?:,)?(?:\\s)?(?:at\\s\\d+)?(?:-\\d+)?)', html_text, re.IGNORECASE)\n",
    "    \n",
    "    mpep = re.findall(r'\\bMPEP(?:\\s)?(?:§\\s)?(?:chapter\\s)?(?:\\d+)(?:\\.\\d+)?\\b', html_text, re.IGNORECASE)\n",
    "    \n",
    "    print(citations)\n",
    "    \n",
    "    return statutes, citations, mpep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a3da1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_references(html_text, statutes, citations, mpep):\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "    bs_text = soup.get_text(separator=' ')\n",
    "    \n",
    "    cleaned_text = re.sub(r'(ante|supra|infra|id)(?:,)?(\\s+)(at\\s\\d+)(?:-\\d+)?', 'CITATION_PLACEHOLDER', bs_text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Replace identified statutes, citations, and MPEP references\n",
    "    cleaned_references = {\n",
    "        'statutes': {},\n",
    "        'citations': {},\n",
    "        'mpep': {}\n",
    "    }\n",
    "\n",
    "    for statute in statutes:\n",
    "        cleaned_text = cleaned_text.replace(statute, 'STATUTE_PLACEHOLDER ')\n",
    "        cleaned_references['statutes'][statute] = 'STATUTE_PLACEHOLDER'\n",
    "\n",
    "    for citation in citations:\n",
    "        cleaned_text = cleaned_text.replace(citation, 'CITATION_PLACEHOLDER ')\n",
    "        cleaned_references['citations'][citation] = 'CITATION_PLACEHOLDER'\n",
    "\n",
    "    for mpep_ref in mpep:\n",
    "        cleaned_text = cleaned_text.replace(mpep_ref, 'MPEP_PLACEHOLDER ')\n",
    "        cleaned_references['mpep'][mpep_ref] = 'MPEP_PLACEHOLDER'\n",
    "\n",
    "    #print(cleaned_text)\n",
    "    return cleaned_text, cleaned_references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9b768a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_tokenize(cleaned_text):\n",
    "    # Remove HTML tags\n",
    "    print(f\"Incoming cleaned text: {cleaned_text}\")\n",
    "    soup = BeautifulSoup(cleaned_text, 'html.parser')\n",
    "    processed_text = soup.get_text(separator=' ')\n",
    "    \n",
    "    print(processed_text)\n",
    "    \n",
    "    # Tokenize using WordPunctTokenizer (words and subwords)\n",
    "    tokenizer = WordPunctTokenizer()\n",
    "    tokens = tokenizer.tokenize(processed_text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word.lower() for word in tokens if word.isalnum() and word.lower() not in stop_words]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad73a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_citations_clean_and_tokenize(html_text):\n",
    "    \n",
    "     # Remove line breaks\n",
    "    html_text_no_space = html_text.replace('\\n', ' ').replace('\\r', '').replace(\"'\", '')\n",
    "    # Remove extra spaces\n",
    "    cleaned_strings = re.sub(' +', ' ', html_text_no_space)\n",
    "    \n",
    "    if cleaned_strings == previous_text:\n",
    "        return cleaned_strings\n",
    "    \n",
    "    print(f\"Cleaned strings: {cleaned_strings}\")\n",
    "    \n",
    "    statutes, citations, mpep = extract_references(cleaned_strings)\n",
    "    \n",
    "    cleaned_text, cleaned_references = clean_references(cleaned_strings, statutes, citations, mpep)\n",
    "    \n",
    "    tokens = clean_and_tokenize(cleaned_text)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb9c057",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_text = \"<p>This is an example HTML text with 35 U.S.C. § 101, 383 U.S. 1, 10-11, 86 S. Ct. 684, 15 L. Ed. 2d 545 (1966), and MPEP § 602.01.</p>\"\n",
    "\n",
    "tokens = remove_citations_clean_and_tokenize(html_text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aab1499",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_text = \"<p>This is an example HTML text with 35 U.S.C. § 101, 383 U.S. 1, 10-11, 86 S. Ct. 684, 15 L. Ed. 2d 545 (1966), and MPEP § 602.01.</p>\"\n",
    "cleaned_text, cleaned_references = clean_references(html_text)\n",
    "print(cleaned_text)\n",
    "print(cleaned_references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ada3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"<p>This is an example HTML text with 35 U.S.C. § 101, 383 U.S. 1, 10-11, 86 S. Ct. 684, 15 L. Ed. 2d 545 (1966), and MPEP § 602.01.</p>\"\n",
    "\n",
    "statutes, citations, mpep = extract_references(text)\n",
    "\n",
    "print(\"Statutes:\", statutes)\n",
    "print(\"Citations:\", citations)\n",
    "print(\"MPEP:\", mpep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10035dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_text = \"\"\"\n",
    "'<opinion type=\"concurrence\">\\n'\n",
    "                  '<author id=\"b881-11\">Justice Breyer,</author>\\n'\n",
    "                  '<p id=\"ALrX\">with whom Justice Scalia joins as to Part II, '\n",
    "                  'concurring in the judgment.</p>\\n'\n",
    "                  '<p id=\"b881-12\">I</p>\\n'\n",
    "                  '<p id=\"b881-13\">I agree with Justice Stevens that a '\n",
    "                  '“general method of engaging in business transactions” is '\n",
    "                  'not a patentable “process” within the meaning of 35 U.S.C. '\n",
    "                  '§ 101. <em>Ante, </em>at 614, 177 L. Ed. 2d, at 809 '\n",
    "                  '(opinion concurring in judgment). This Court has never '\n",
    "                  'be<page-number citation-index=\"1\" '\n",
    "                  'label=\"836\">*836</page-number>fore held that so-called '\n",
    "                  '“business methods” are patentable, and, in my view, the '\n",
    "                  'text, history, and purposes of the Patent Act make clear '\n",
    "                  'that they are not. <em>Ante, </em>at 621-657, 177 L. Ed. '\n",
    "                  '2d, at 813-835 (same). I would therefore decide this case '\n",
    "                  'on that ground, and I join Justice Stevens’ opinion in '\n",
    "                  'full.</p>\\n'\n",
    "                  '<p id=\"b882-4\">I write separately, however, in order to '\n",
    "                  'highlight the substantial <em>agreement </em>among many '\n",
    "                  'Members of the Court on many of the fundamental issues of '\n",
    "                  'patent law raised by this case. In light of the need for '\n",
    "                  'clarity and settled law in this highly technical area, I '\n",
    "                  'think it appropriate to do so.</p>\\n'\n",
    "                  '<p id=\"b882-5\">[561 U.S. 658]</p>\\n'\n",
    "                  '<p id=\"b882-6\">II</p>\\n'\n",
    "                  '<p id=\"b882-7\">In addition to the Court’s unanimous '\n",
    "                  'agreement that the claims at issue here are unpatentable '\n",
    "                  'abstract ideas, it is my view that the following four '\n",
    "                  'points are consistent with both the opinion of the Court '\n",
    "                  'and Justice Stevens’ opinion concurring in the '\n",
    "                  'judgment:</p>\\n'\n",
    "                  '<p id=\"b882-8\"><em>First, </em>although the text of § 101 '\n",
    "                  'is broad, it is not without limit. See <em>ante, </em>at '\n",
    "                  '601-602, 177 L. Ed. 2d, at 800-801 (opinion of the Court); '\n",
    "                  '<em>ante, </em>at 622, 177 L. Ed. 2d, at 813-814 (opinion '\n",
    "                  'of Stevens, J.). “[T]he underlying policy of the patent '\n",
    "                  'system [is] that ‘the things which are worth to the public '\n",
    "                  'the embarrassment of an exclusive patent,’ . . . must '\n",
    "                  'outweigh the restrictive effect of the limited patent '\n",
    "                  'monopoly.” <em>Graham </em>v. <em>John Deere Co. of Kansas '\n",
    "                  'City, </em>383 U.S. 1, 10-11, 86 S. Ct. 684, 15 L. Ed. 2d '\n",
    "                  '545 (1966) (quoting Letter from Thomas Jefferson to Isaac '\n",
    "                  'McPherson (Aug. 13, 1813), in 6 Writings of Thomas '\n",
    "                  'Jefferson 181 (H. Washington ed.)). The Court has thus been '\n",
    "                  'careful in interpreting the Patent Act to “determine not '\n",
    "                  'only what is protected, but also what is free for all to '\n",
    "                  'use.” <em>Bonito Boats, Inc. </em>v. <em>Thunder Craft '\n",
    "                  'Boats, Inc., </em>489 U.S. 141, 151, 109 S. Ct. 971, 103 L. '\n",
    "                  'Ed. 2d 118 (1989). In particular, the Court has long held '\n",
    "                  'that “[p]henomena of nature, though just discovered, mental '\n",
    "                  'processes, and abstract intellectual concepts are not '\n",
    "                  'patentable” under § 101, since allowing individuals to '\n",
    "                  'patent these fundamental principles would “wholly preempt” '\n",
    "                  'the public’s access to the “basic tools of scientific and '\n",
    "                  'technological work.” <em>Gottschalk </em>v. <em>Benson, '\n",
    "                  '</em>409 U.S. 63, 67, 72, 93 S. Ct. 253, 34 L. Ed. 2d 273 '\n",
    "                  '(1972); see also, <em>e.g., Diamond </em>v. <em>Diehr, '\n",
    "                  '</em>450 U.S. 175, 185, 101 S. Ct. 1048, 67 L. Ed. 2d 155 '\n",
    "                  '(1981); <em>Diamond </em>v. <em>Chakrabarty, </em>447 U.S. '\n",
    "                  '303, 309, 100 S. Ct. 2204, 65 L. Ed. 2d 144 (1980).</p>\\n'\n",
    "                  '<p id=\"b882-11\"><em>Second, </em>in a series of cases that '\n",
    "                  'extend back over a century, the Court has stated that '\n",
    "                  '“[t]ransformation and reduction of an article to a '\n",
    "                  'different state or thing is <em>the clue </em>to the '\n",
    "                  'patent-ability of a process claim that does not include '\n",
    "                  'particular machines.” <em>Diehr, supra, </em>at 184, 101 S. '\n",
    "                  'Ct. 1048, 67 L. Ed. 2d 155 (emphasis added; internal '\n",
    "                  'quotation marks omitted); see also, <em>e.g., Benson, '\n",
    "                  'supra, </em>at 70, 93 S. Ct. 253, 34 L. Ed. 2d 273; '\n",
    "                  '<em>Parker </em>v. <em>Flook, </em>437 U.S. 584, 588, n. 9, '\n",
    "                  '98 S. Ct. 2522, 57 L. Ed. 2d 451 (1978); <em>Cochrane '\n",
    "                  '</em>v. <em>Deener, </em>94 U.S. 780, 788, 24 L. Ed. 139 '\n",
    "                  '(1877). Application of</p>\\n'\n",
    "                  '<p id=\"b882-12\">[561 U.S. 659]</p>\\n'\n",
    "                  '<p id=\"b882-13\">this test, the so-called '\n",
    "                  '“machine-or-transformation test,” has thus repeatedly '\n",
    "                  'helped the Court to determine what is “a patentable '\n",
    "                  '‘process.’ ” <em>Flook, supra, </em>at 589, 98 S. Ct. 2522, '\n",
    "                  '57 L. Ed. 2d 451.</p>\\n'\n",
    "                  '<p id=\"b882-15\"><em>Third, </em>while the '\n",
    "                  'machine-or-transformation test has always been a “useful '\n",
    "                  'and important clue,” it has never been the “sole test” for '\n",
    "                  'deter<page-number citation-index=\"1\" '\n",
    "                  'label=\"837\">*837</page-number>mining patentability. '\n",
    "                  '<em>Ante, </em>at 604, 177 L. Ed. 2d, at 803; see also '\n",
    "                  '<em>ante, </em>at 614, 177 L. Ed. 2d, at 808 (opinion of '\n",
    "                  'Stevens, J.); <em>Benson, supra, </em>at 71, 93 S. Ct. 253, '\n",
    "                  '34 L. Ed. 2d 273 (rejecting the argument that “no process '\n",
    "                  'patent could ever qualify” for protection under § 101 “if '\n",
    "                  'it did not meet the [machine-or-transformation] '\n",
    "                  'requirements”). \n",
    "                    \"\"\"\n",
    "tokens = remove_citations_clean_and_tokenize(html_text)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc73c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_references_test(html_text):\n",
    "    \n",
    "    statutes = re.findall(r'\\b\\d+\\sU\\.S\\.C\\.\\s§\\s\\d+\\b', html_text, re.IGNORECASE)\n",
    "    \n",
    "    citations = re.findall(r'\\b(\\d+\\s[A-Za-z\\s\\.\\d+]+(?:\\d+)?(?:,)?(?:\\s)?(?:at\\s\\d+)?(?:-\\d+)?)', html_text, re.IGNORECASE)\n",
    "    \n",
    "    mpep = re.findall(r'\\bMPEP(?:\\s)?(?:§\\s)?(?:chapter\\s)?(?:\\d+)(?:\\.\\d+)?\\b', html_text, re.IGNORECASE)\n",
    "    \n",
    "    return cleaned_text, statutes, citations, mpep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26553867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_replace_citations(text):\n",
    "    '''\n",
    "    Input text including legal citations.\n",
    "    Clean text using eyecite.clean_text.\n",
    "    \n",
    "    '''\n",
    "    # Use eyecite to remove white space and clean text using eyecite.clean_text.\n",
    "    clean_text = eyecite.clean_text(text, ['html', 'all_whitespace'])\n",
    "    \n",
    "    # Use eyecite to find legal citations in the text\n",
    "    citations = eyecite.get_citations(clean_text)\n",
    "\n",
    "    return citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0c67bf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_replace_citations(text):\n",
    "    '''\n",
    "    Input text including legal citations.\n",
    "    Clean text using eyecite.clean_text.\n",
    "    \n",
    "    '''\n",
    "    # Use eyecite to remove white space and clean text using eyecite.clean_text.\n",
    "    cleaned_text = clean_text(text, ['html', 'all_whitespace'])\n",
    "    \n",
    "    # Use eyecite to find legal citations in the text\n",
    "    citations = get_citations(cleaned_text)\n",
    "    \n",
    "    # Placeholder for each type of citation\n",
    "    placeholders = {\n",
    "        'FullLawCitation': 'FULL_LAW_CITATION_PLACEHOLDER',\n",
    "        'FullCaseCitation': 'FULL_CASE_CITATION_PLACEHOLDER',\n",
    "        'ShortCaseCitation': 'SHORT_CASE_CITATION_PLACEHOLDER',\n",
    "        'IdCitation': 'ID_CITATION',\n",
    "        'SupraCitation': 'SUPRA_CITATION',\n",
    "        'UnknownCitation': 'UNKNOWN_CITATION_PLACEHOLDER',\n",
    "    }\n",
    "\n",
    "    output_text = cleaned_text\n",
    "    \n",
    "    # Replace each citation with the corresponding placeholder\n",
    "    for citation in citations:\n",
    "        citation_type = type(citation).__name__\n",
    "        print(citation_type)\n",
    "        \n",
    "        placeholder = placeholders.get(citation_type, '')\n",
    "\n",
    "        if citation_type == 'FullCaseCitation':\n",
    "            output_text = output_text.replace(citation.matched_text(), placeholder)\n",
    "            print(citation.matched_text())\n",
    "        elif citation_type == 'FullLawCitation':\n",
    "            output_text = output_text.replace(citation.matched_text(), placeholder)\n",
    "            print(citation.matched_text())\n",
    "        elif citation_type == 'ShortCaseCitation':\n",
    "            output_text = output_text.replace(citation.matched_text(), placeholder)\n",
    "            print(citation.matched_text())\n",
    "        #elif citation_type == 'IdCitation':\n",
    "        #    output_text = output_text.replace(citation.matched_text(), placeholder)\n",
    "        #    print(citation.matched_text())\n",
    "        #elif citation_type == 'SupraCitation':\n",
    "        #    output_text = output_text.replace(citation.matched_text(), placeholder)\n",
    "        #    print(citation.matched_text())\n",
    "        #elif citation_type == 'UnknownCitation':\n",
    "        #    output_text = output_text.replace(citation.matched_text(), placeholder)\n",
    "        #    print(citation.matched_text())\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "            \n",
    "    return citations, output_text, cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c63cbba7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FullLawCitation\n",
      "Public Law 112-29, 125\n",
      "UnknownCitation\n",
      "IdCitation\n",
      "Id.\n",
      "SupraCitation\n",
      "supra,\n",
      "supra,\n",
      "ShortCaseCitation\n",
      "177 L. Ed. 2d, at 809\n",
      "UnknownCitation\n",
      "FullCaseCitation\n",
      "489 U.S. 141\n",
      "FullCaseCitation\n",
      "109 S. Ct. 971\n",
      "FullCaseCitation\n",
      "103 L. Ed. 2d 118\n",
      "[FullLawCitation('Public Law 112-29, 125', groups={'reporter': 'Public Law', 'title': '112-29', 'section': '125'}, metadata=FullLawCitation.Metadata(parenthetical=None, pin_cite=None, year=None, publisher=None, day=None, month=None)),\n",
      " UnknownCitation('§', metadata=CitationBase.Metadata(parenthetical=None)),\n",
      " IdCitation('Id.', metadata=IdCitation.Metadata(parenthetical=None, pin_cite='at 410')),\n",
      " SupraCitation('supra,', metadata=SupraCitation.Metadata(parenthetical=None, antecedent_guess='765', pin_cite='1909', volume=None)),\n",
      " ShortCaseCitation('177 L. Ed. 2d, at 809', groups={'volume': '177', 'reporter': 'L. Ed. 2d', 'page': '809'}, metadata=ShortCaseCitation.Metadata(parenthetical=None, pin_cite=None, year=None, court=None, antecedent_guess='465')),\n",
      " UnknownCitation('§', metadata=CitationBase.Metadata(parenthetical=None)),\n",
      " FullCaseCitation('489 U.S. 141', groups={'volume': '489', 'reporter': 'U.S.', 'page': '141'}, metadata=FullCaseCitation.Metadata(parenthetical=None, pin_cite='151', year='1989', court='scotus', plaintiff='Inc.', defendant='Thunder Craft Boats, Inc.', extra='109 S. Ct. 971, 103 L. Ed. 2d 118')),\n",
      " FullCaseCitation('109 S. Ct. 971', groups={'volume': '109', 'reporter': 'S. Ct.', 'page': '971'}, metadata=FullCaseCitation.Metadata(parenthetical=None, pin_cite=None, year='1989', court='scotus', plaintiff='Inc.', defendant='Thunder Craft Boats, Inc., 489 U.S. 141, 151', extra='103 L. Ed. 2d 118')),\n",
      " FullCaseCitation('103 L. Ed. 2d 118', groups={'volume': '103', 'reporter': 'L. Ed. 2d', 'page': '118'}, metadata=FullCaseCitation.Metadata(parenthetical=None, pin_cite=None, year='1989', court=None, plaintiff='Inc.', defendant='Thunder Craft Boats, Inc., 489 U.S. 141, 151, 109 S. Ct. 971', extra=None))]\n",
      "Art. 1, Sec. 8. Leahy-Smith America Invents Act (AIA), Public Law 112-29, 125 Stat. 284. 35 U.S.C. 1 Establishment. ante, at 510-980, infra at 732, mpep § 701.32, mpep chapter 2100, Id. at 410, id at 765, supra, 1909, id, 465 177 L. Ed. 2d, at 809 mpep § 701.32, mpep chapter 2100 Bonito Boats, Inc. v. Thunder Craft Boats, Inc., 489 U.S. 141, 151, 109 S. Ct. 971, 103 L. Ed. 2d 118 (1989) eyecite \n",
      "Art. 1, Sec. 8. Leahy-Smith America Invents Act (AIA), FULL_LAW_CITATION_PLACEHOLDER Stat. 284. 35 U.S.C. 1 Establishment. ante, at 510-980, infra at 732, mpep § 701.32, mpep chapter 2100, ID_CITATION at 410, id at 765, SUPRA_CITATION 1909, id, 465 SHORT_CASE_CITATION_PLACEHOLDER mpep § 701.32, mpep chapter 2100 Bonito Boats, Inc. v. Thunder Craft Boats, Inc., FULL_CASE_CITATION_PLACEHOLDER, 151, FULL_CASE_CITATION_PLACEHOLDER, FULL_CASE_CITATION_PLACEHOLDER (1989) eyecite \n"
     ]
    }
   ],
   "source": [
    "citations, text_with_placeholders, cleaned_text = extract_and_replace_citations(sample_text)\n",
    "\n",
    "pprint(citations)\n",
    "#print(f'Extracted {len(citations)} citations.\\n')\n",
    "#print(f'First citation:\\n {citations[4]}\\n')\n",
    "\n",
    "#citations[4].token\n",
    "\n",
    "print(cleaned_text)\n",
    "print(text_with_placeholders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7812ad0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__pdoc__', '__spec__', 'annotate', 'annotate_citations', 'clean', 'clean_text', 'find', 'get_citations', 'helpers', 'models', 'regexes', 'resolve', 'resolve_citations', 'tokenizers', 'utils']\n"
     ]
    }
   ],
   "source": [
    "print(dir(eyecite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c855d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BACKWARD_SEEK', 'CaseCitation', 'CitationBase', 'CitationToken', 'FullCaseCitation', 'FullJournalCitation', 'FullLawCitation', 'List', 'MAX_MATCH_CHARS', 'Optional', 'POST_FULL_CITATION_REGEX', 'POST_JOURNAL_CITATION_REGEX', 'POST_LAW_CITATION_REGEX', 'POST_SHORT_CITATION_REGEX', 'ParagraphToken', 'ResourceCitation', 'StopWordToken', 'Token', 'Tokens', 'Tuple', 'YEAR_REGEX', '__annotations__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '_highest_valid_year', 'add_defendant', 'add_journal_metadata', 'add_law_metadata', 'add_post_citation', 'cast', 'clean_pin_cite', 'courts', 'date', 'disambiguate_reporters', 'extract_pin_cite', 'get_court_by_paren', 'get_year', 'joke_cite', 'match_on_tokens', 'process_parenthetical', 're', 'strip_punct']\n"
     ]
    }
   ],
   "source": [
    "print(dir(eyecite.helpers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d9234426",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = '''Art. 1, Sec. 8. Leahy-Smith America Invents Act (AIA), Public Law 112-29, 125 Stat. 284., 35 U.S.C. 1 Establishment.\n",
    "ante,  at 510-980, infra at 732, mpep § 701.32, mpep chapter 2100, Id. at 410, id at 765, supra, 1909, id, 465\n",
    "177 L. Ed. 2d, at 809\n",
    "mpep § 701.32, mpep chapter 2100\n",
    "Bonito Boats, Inc. v. Thunder Craft Boats, Inc., 489 U.S. 141, 151, 109 S. Ct. 971, 103 L. Ed. 2d 118 (1989)\n",
    "eyecite\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28af111c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_replace_citations(text):\n",
    "    '''\n",
    "    Input text including legal citations.\n",
    "    Clean text using eyecite.clean_text.\n",
    "    \n",
    "    '''\n",
    "    # Use eyecite to remove white space and clean text using eyecite.clean_text.\n",
    "    cleaned_text = clean_text(text, ['html', 'all_whitespace'])\n",
    "    \n",
    "    # Use eyecite to find legal citations in the text\n",
    "    citations = get_citations(cleaned_text)\n",
    "\n",
    "    # Placeholder for each type of citation\n",
    "    placeholders = {\n",
    "        'FullLawCitation': 'FULL_LAW_CITATION_PLACEHOLDER',\n",
    "        'FullCaseCitation': 'FULL_CASE_CITATION_PLACEHOLDER',\n",
    "        'ShortCaseCitation': 'SHORT_CASE_CITATION_PLACEHOLDER',\n",
    "        'UnknownCitation': 'UNKNOWN_CITATION_PLACEHOLDER',\n",
    "    }\n",
    "\n",
    "    # Replace each citation with the corresponding placeholder\n",
    "    for citation in citations:\n",
    "        citation_type = type(citation).__name__\n",
    "        placeholder = placeholders.get(citation_type, '')\n",
    "        \n",
    "        #print(citation.span)\n",
    "        #print(citation.span_start)\n",
    "        #print(citation.span_end)\n",
    "        #print(f\"Matched Text: {citation.matched_text}\")\n",
    "        #print(f\"Full Span: {citation.__match_args__}\")\n",
    "        #for attr in dir(citation):\n",
    "        #   print(attr)\n",
    "        #parenthetical = citation.metadata.parenthetical\n",
    "        #print(f\"Parenthetical: {parenthetical}\")\n",
    "\n",
    "        start = citation.span_start\n",
    "        end = citation.span_end\n",
    "\n",
    "        ouput_text = cleaned_text[:start] + placeholder + cleaned_text[end:]\n",
    "\n",
    "    return citations, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa2134ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'FullCaseCitation' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#citation = <bound method CitationBase.matched_text of FullLawCitation('Public Law 112-29, 125', groups={'reporter': 'Public Law', 'title': '112-29', 'section': '125'}, metadata=FullLawCitation.Metadata(parenthetical=None, pin_cite=None, year=None, publisher=None, day=None, month=None))>\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Accessing the matched text\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m citation[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m citations: \n\u001b[1;32m      6\u001b[0m     matched_text \u001b[38;5;241m=\u001b[39m citation\u001b[38;5;241m.\u001b[39mmatched_text()\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(matched_text)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'FullCaseCitation' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "#citation = <bound method CitationBase.matched_text of FullLawCitation('Public Law 112-29, 125', groups={'reporter': 'Public Law', 'title': '112-29', 'section': '125'}, metadata=FullLawCitation.Metadata(parenthetical=None, pin_cite=None, year=None, publisher=None, day=None, month=None))>\n",
    "\n",
    "\n",
    "# Accessing the matched text\n",
    "for citation in citations: \n",
    "    matched_text = citation.matched_text()\n",
    "    print(matched_text)\n",
    "\n",
    "# Accessing groups\n",
    "groups = citation.groups\n",
    "\n",
    "# Accessing specific group values\n",
    "reporter = citation.groups['reporter']\n",
    "title = citation.groups['title']\n",
    "section = citation.groups['section']\n",
    "\n",
    "# Accessing metadata\n",
    "metadata = citation.metadata\n",
    "\n",
    "# Accessing specific metadata values\n",
    "parenthetical = citation.metadata.parenthetical\n",
    "pin_cite = citation.metadata.pin_cite\n",
    "year = citation.metadata.year\n",
    "publisher = citation.metadata.publisher\n",
    "day = citation.metadata.day\n",
    "month = citation.metadata.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54889c22",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "citations = extract_and_replace_citations(sample_text)\n",
    "\n",
    "for citation in citations:\n",
    "    print(f\"Type: {type(citation).__name__}\")\n",
    "    print(f\"Attributes and methods: {dir(citation)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9242bf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citation: Public Law 112-29, 125\n",
      "Type of First Citation: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "first_citation = None\n",
    "\n",
    "for citation in citations:\n",
    "    matched_text = citation.matched_text()\n",
    "    #print(matched_text)\n",
    "\n",
    "    # Store the matched text of the first citation\n",
    "    if first_citation is None:\n",
    "        first_citation = matched_text\n",
    "        break\n",
    "\n",
    "# Now 'first_citation' contains the matched text of the first citation\n",
    "print(\"First Citation:\", first_citation)\n",
    "\n",
    "first_citation_type = type(first_citation)\n",
    "print(\"Type of First Citation:\", first_citation_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7649922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_legal_tokens(text):\n",
    "    # Define regular expressions for different legal citation patterns\n",
    "    statute_pattern = r'\\d+\\s+[A-Za-z]+\\s+\\d+'\n",
    "    usc_pattern = r'\\d+\\s+U\\.S\\.C\\.\\s+\\d+'\n",
    "    manual_pattern = r'mpep\\s+§\\s+\\d+\\.\\d+'\n",
    "    chapter_pattern = r'mpep\\s+chapter\\s+\\d+'\n",
    "    short_citation_pattern = r'(ante|at|infra|Id\\.|supra)\\s+at?\\s*\\d+-\\d+'\n",
    "\n",
    "    # Combine patterns into a single pattern\n",
    "    combined_pattern = f'({statute_pattern}|{usc_pattern}|{manual_pattern}|{chapter_pattern}|{short_citation_pattern})'\n",
    "\n",
    "    # Find all matches in the text\n",
    "    matches = re.findall(combined_pattern, text)\n",
    "    \n",
    "    # Extract labeled tokens from matches\n",
    "    labeled_tokens = []\n",
    "    for match in matches:\n",
    "        labeled_token = {k: v for k, v in match.groupdict().items() if v is not None}\n",
    "        labeled_tokens.append(labeled_token)\n",
    "\n",
    "    return labeled_tokens\n",
    "\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "faa250d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'groupdict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m legal_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mextract_legal_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(legal_tokens)\n",
      "Cell \u001b[0;32mIn[88], line 18\u001b[0m, in \u001b[0;36mextract_legal_tokens\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     16\u001b[0m labeled_tokens \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m match \u001b[38;5;129;01min\u001b[39;00m matches:\n\u001b[0;32m---> 18\u001b[0m     labeled_token \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupdict\u001b[49m()\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[1;32m     19\u001b[0m     labeled_tokens\u001b[38;5;241m.\u001b[39mappend(labeled_token)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m labeled_tokens\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'groupdict'"
     ]
    }
   ],
   "source": [
    "legal_tokens = extract_legal_tokens(sample_text)\n",
    "print(legal_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6376a5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = '''Art. 1, Sec. 8. Leahy-Smith America Invents Act (AIA), Public\\nLaw 112-29, 125\n",
    "Stat. 284. 35 U.S.C. 1 Establishment.\n",
    "\n",
    "ante,  at 510-980, infra at 732, mpep § 701.32, mpep chapter 2100, Id. at 656, id. at 987, ID, 1009.\n",
    "\n",
    "177 L. Ed. 2d, at 809\n",
    "\n",
    "Ante, at 614, 177 L. Ed. 2d, at 809, 197 L. Ed. 2d, at 809-901, [561 U.S. 658], MPEP 2000\n",
    "Bonito Boats, Inc. v. Thunder Craft Boats, Inc., 489 U.S. 141, 151, 109 S. Ct. 971, 103 L. Ed. 2d 118 (1989)\n",
    "Gottschalk v. Benson, 409 U.S. 63, 67, 72, 93 S. Ct. 253, 34 L. Ed. 2d 273 (1972)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258f70b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = '''\"INTRODUCTION\\n  Constitutional Basis\\nThe Constitution of the United States\n",
    "provides:\\n“Art. 1, Sec. 8. The Congress shall have power . . .\\nTo promote the progress\n",
    "of science and useful arts,\\nby securing for limited times to authors and inventors\\nthe\n",
    "exclusive right to their respective writings and\\ndiscoveries.”\\n  Statutes\\nPursuant to\n",
    "the provision of the Constitution,\\nCongress has over the years passed a number of\\nstatutes\n",
    "under which the U.S. Patent and Trademark\\nOffice (USPTO) is organized and our patent system\\ni\n",
    "s established. The provisions of the statutes can in\\nno way be changed or waived by the USPTO.\n",
    "\\nPrior to January 1, 1953, the law relating to patents\\nconsisted of various sections of the\n",
    "Revised Statutes\\nof 1874, derived from the Patent Act of 1870 and\\nnumerous amendatory and \n",
    "additional acts.\\nBy an Act of Congress approved July 19, 1952,\\nwhich came into effect on \n",
    "January 1, 1953, the patent\\nlaws were revised and codified in Title 35 of the\\nUnited States Code.\n",
    "In referring to a particular\\nsection of the patent code the citation is given, for\\nexample, as, \n",
    "35 U.S.C. 1. The United States Code\\nis available online at http://uscode.house.gov/.\\nUpon occasion, \n",
    "additional provisions pertaining to\\npatents are set forth in a Public Law but are not\\ncodified. \n",
    "Examples are some sections of the\\nLeahy-Smith America Invents Act (AIA), Public\\nLaw 112-29, 125\n",
    "Stat. 284. The Public Laws are\\navailable at www.congress.gov/public-laws.\\nTitle 35 of the United\n",
    "States Code and sections 14,\\n18, and 33 of the AIA are reproduced in Appendix\\nL of the Manual \n",
    "of Patent Examining Procedure\\n(MPEP), however the Public Laws are the\\nauthoritative source and\n",
    "should be consulted if a\\nneed arises to verify the authenticity of the language\\nreproduced in the\n",
    "MPEP. A copy of the consolidated\\npatent laws that incorporates any statutory revisions\\nthat became\n",
    "effective subsequent to the latest\\nrevision of the MPEP is available on the USPTO\\nwebsite at www.\n",
    "uspto.gov/web/offices/pac/mpep/\\nconsolidated_laws.pdf.\\n35 U.S.C. 1 Establishment.\\n  (a) \n",
    "ESTABLISHMENT.— The United States Patent and\\nTrademark Office is established as an agency of the \n",
    "United\\nStates, within the Department of Commerce. In carrying out its\\nfunctions, the United States\n",
    "Patent and Trademark Office shall\\nbe subject to the policy direction of the Secretary of Commerce,\n",
    "\\nbut otherwise shall retain responsibility for decisions regarding\\nthe management and administration\n",
    "of its operations and shall\\nexercise independent control of its budget allocations and\\nexpenditures,\n",
    "personnel decisions and processes, procurements,\\nand other administrative and management functions\n",
    "in\\naccordance with this title and applicable provisions of law. Those\\noperations designed to grant\n",
    "and issue patents and those\\noperations which are designed to facilitate the registration \n",
    "of\\ntrademarks shall be treated as separate operating units within\\nthe Office.\\n\n",
    "\n",
    "ante,  at 510-980, infra at 732, mpep § 701.32, mpep chapter 2100\n",
    "\n",
    "177 L. Ed. 2d, at 809\n",
    "\n",
    "Ante, at 614, 177 L. Ed. 2d, at 809, 197 L. Ed. 2d, at 809-901, [561 U.S. 658], MPEP 2000\n",
    "Bonito Boats, Inc. v. Thunder Craft Boats, Inc., 489 U.S. 141, 151, 109 S. Ct. 971, 103 L. Ed. 2d 118 (1989)\n",
    "Gottschalk v. Benson, 409 U.S. 63, 67, 72, 93 S. Ct. 253, 34 L. Ed. 2d 273 (1972)\n",
    "\n",
    "'''\n",
    "\n",
    "clean_text = eyecite.clean_text(sample_text, [\"all_whitespace\"])\n",
    "\n",
    "citations = eyecite.get_citations(clean_text)\n",
    "\n",
    "text_with_placeholders = extract_and_replace_citations(sample_text)\n",
    "\n",
    "\n",
    "print(citations)\n",
    "print('-----')\n",
    "#print(sample_text)\n",
    "print(clean_text)\n",
    "print('-----')\n",
    "print(text_with_placeholders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35459e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install hyperscan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87763e7",
   "metadata": {},
   "source": [
    "## MPEP PDF to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e84dcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1c2103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pdfs_to_text(folder_path):\n",
    "    \"\"\"\n",
    "    Convert PDF files in the specified folder to text.\n",
    "\n",
    "    Parameters:\n",
    "    - folder_path: The path to the folder containing PDF files.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary mapping filenames to their corresponding text content.\n",
    "    \"\"\"\n",
    "    pdf_texts = {}\n",
    "\n",
    "    # Check if the folder path exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Error: Folder '{folder_path}' does not exist.\")\n",
    "        return pdf_texts\n",
    "\n",
    "    # Loop through PDF files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            pdf_document = None\n",
    "\n",
    "            try:\n",
    "                # Open the PDF file\n",
    "                pdf_document = fitz.open(file_path)\n",
    "\n",
    "                # Extract text from each page\n",
    "                text = \"\"\n",
    "                for page_number in range(pdf_document.page_count):\n",
    "                    page = pdf_document[page_number]\n",
    "                    text += page.get_text()\n",
    "\n",
    "                # Save text content in the dictionary\n",
    "                pdf_texts[filename] = text\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing '{filename}': {str(e)}\")\n",
    "\n",
    "            finally:\n",
    "                # Close the PDF document\n",
    "                if pdf_document is not None:\n",
    "                    pdf_document.close()\n",
    "\n",
    "    return pdf_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ed177b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_tokenize_pdf(text):\n",
    "    processed_texts = {}\n",
    "\n",
    "    # Process each text in the original dictionary\n",
    "    for filename, text in pdf_texts.items():\n",
    "        # Assuming remove_citations_clean_and_tokenize is your function\n",
    "        processed_text = remove_citations_clean_and_tokenize_1(text)\n",
    "        #print(filename)\n",
    "\n",
    "        # Store the processed text in the new dictionary\n",
    "        processed_texts[filename] = processed_text\n",
    "    \n",
    "    return processed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932450db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_citations_clean_and_tokenize_1(html_text, previous_text=None):\n",
    "    # Remove line breaks\n",
    "    html_text_no_space = html_text.replace('\\n', ' ').replace('\\r', '').replace(\"'\", '')\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    cleaned_strings = re.sub(' +', ' ', html_text_no_space)\n",
    "    \n",
    "    #print(f\"Cleaned strings: {cleaned_strings}\")\n",
    "    \n",
    "    # Terminate recursion if no change in text\n",
    "    if cleaned_strings == previous_text:\n",
    "        return cleaned_strings\n",
    "    \n",
    "    statutes, citations, mpep = extract_references(cleaned_strings)\n",
    "    \n",
    "    cleaned_text, cleaned_references = clean_references(cleaned_strings, statutes, citations, mpep)\n",
    "    \n",
    "    tokens = clean_and_tokenize(cleaned_text)\n",
    "    \n",
    "    # Recursive call with updated text\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975ac45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/Users/curtiswadsworth/NL_Notebooks/MPEP_pdf_1\"\n",
    "pdf_texts = convert_pdfs_to_text(folder_path)\n",
    "print(pdf_texts)\n",
    "\n",
    "processed_texts = clean_and_tokenize_pdf(pdf_texts)\n",
    "\n",
    "print(processed_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b26974da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched \"id.\" in \"id.\"\n",
      "Matched \"id,\" in \"id,\"\n",
      "Matched \"ibid.\" in \"ibid.\"\n",
      "Matched \"ibid,\" in \"ibid,\"\n",
      "Matched \"id\" in \"id\"\n",
      "Matched \"ibid\" in \"ibid\"\n",
      "Matched \"id.,\" in \"id.,\"\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "pattern = re.compile(r\"(id(?:\\.)?,?|ibid(?:\\.)?,?)\")\n",
    "\n",
    "# Test cases\n",
    "test_strings = [\"id.\", \"id,\", \"ibid.\", \"ibid,\", \"id\", \"ibid\", \"id.,\"]\n",
    "\n",
    "for test_string in test_strings:\n",
    "    match = pattern.search(test_string)\n",
    "    if match:\n",
    "        print(f'Matched \"{match.group()}\" in \"{test_string}\"')\n",
    "    else:\n",
    "        print(f'No match in \"{test_string}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03489722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched: MPEP\n",
      "Matched: mpep\n",
      "Matched: m.p.e.p\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MPEP_REGEX = re.compile(r'\\bmpep\\b|\\bm\\.p\\.e\\.p\\b', flags=re.IGNORECASE)\n",
    "matches = MPEP_REGEX.finditer(\"MPEP is an example, mpep is annother, and m.p.e.p example.\")\n",
    "\n",
    "for match in matches:\n",
    "    print(f'Matched: {match.group()}')  # Access the capturing group)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
